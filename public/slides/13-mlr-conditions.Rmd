---
title: "Checking conditions for MLR"
author: "Prof. Maria Tackett"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "sta210-slides.css"
    logo: img/sta199-sticker-icon.png
    lib_dir: libs/font-awesome
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%" 
      ratio: "16:9"
editor_options: 
  chunk_output_type: console
---

```{r child = "setup.Rmd"}
```

class: middle, center

## [Click here for PDF of slides](13-mlr-conditions.pdf)

```{r}
library(tidyverse)
library(broom)
library(knitr)
library(patchwork)
```


---

## Example: SAT Averages by State

- This data set contains the average SAT score (out of 1600) and other variables that may be associated with SAT performance for each of the 50 U.S. states. The data is based on test takers for the 1982 exam.

- Response variable:
  + <font class="vocab">`SAT`</font>: average total SAT score

.footnote[Data comes from `case1201` data set in the `Sleuth3` package]

---

## SAT Averages: Predictors

- <font class="vocab">`Takers`</font>: percentage of high school seniors who took exam
- <font class="vocab">`Income`</font>: median income of families of test-takers ($ hundreds)
- <font class="vocab">`Years`</font>: average number of years test-takers had formal education in social sciences, natural sciences, and humanities
- <font class="vocab">`Public`</font>: percentage of test-takers who attended public high schools
- <font class="vocab">`Expend`</font>: total state expenditure on high schools ($ hundreds per student)
- <font class="vocab">`Rank`</font>: median percentile rank of test-takers within their high school classes

---

## Model

```{r}
sat_scores <- Sleuth3::case1201 %>%
  select(-State) 
```

```{r}
sat_model <- lm(SAT ~ ., data = sat_scores)
tidy(sat_model) %>%
  kable(format = "markdown", digits = 3)
```


```{r echo = F}
sat_aug <- augment(sat_model) %>%
  mutate(obs_num = row_number()) #add observation number for plots
```

---

## Model conditions

1. .vocab[Linearity: ]There is a linear relationship between the response and predictor variables.

2. .vocab[Constant Variance: ]The variability about the least squares line is generally constant.

3. .vocab[Normality: ]The distribution of the residuals is approximately normal.

4. .vocab[Independence: ]The residuals are independent from each other.

---

## Residuals vs. predicted values

```{r, fig.height = 3}
ggplot(data = sat_aug, aes(x = .fitted, y = .resid)) + 
  geom_point(alpha = 0.7) + 
  geom_hline(yintercept = 0, color = "red") +
  labs(x = "Predicted values", 
       y = "Residuals") +
  theme_bw() +
  theme(axis.title=element_text(size=14))
```

---

## Linearity: Residuals vs. predicted

```{r, fig.height = 2.5}
ggplot(data = sat_aug, aes(x = .fitted, y = .resid)) + 
  geom_point(alpha = 0.7) + 
  geom_hline(yintercept = 0, color = "red") +
  labs(x = "Predicted values", 
       y = "Residuals") +
  theme_bw() +
  theme(axis.title=element_text(size=14))
```

---

## Linearity: Residuals vs. each predictor

If there is some pattern in the plot of residuals vs. predicted values, you can look at individual plots of residuals vs. each predictor to try to identify the issue.

```{r, fig.height = 3}
p1 <- ggplot(data = sat_aug, aes(x = Takers, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0, color = "red") + 
  theme_bw()

p2 <- ggplot(data = sat_aug, aes(x = Income, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0, color = "red") + 
  theme_bw()

p3 <- ggplot(data = sat_aug, aes(x = Years, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0, color = "red") + 
  theme_bw()

p4 <- ggplot(data = sat_aug, aes(x = Public, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0, color = "red") + 
  theme_bw()

p5 <- ggplot(data = sat_aug, aes(x = Expend, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0, color = "red") + 
  theme_bw()

p6 <- ggplot(data = sat_aug, aes(x = Rank, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0, color = "red") + 
  theme_bw()

(p1 + p2 + p3) / (p4 + p5 + p6)
```

---

## Checking linearity 

`r emo::ji("white_check_mark")` The plot of residuals vs. predicted shows no distinguishable pattern 

`r emo::ji("white_check_mark")` The plots of residuals vs. each predictor variable are generally fine; perhaps look into `Years` more closely. 

.vocab[The linearity condition is generally satisfied.] 

---

## Checking constant variance

```{r, fig.height = 2.5}
ggplot(data = sat_aug, aes(x = .fitted, y = .resid)) + 
  geom_point(alpha = 0.7) + 
  geom_hline(yintercept = 0, color = "red") +
  labs(x = "Predicted values", 
       y = "Residuals") +
  theme_bw() +
  theme(axis.title=element_text(size=14))
```

`r emo::ji("white_check_mark")` The vertical spread of the residuals is relatively constant across the plot. .vocab[The constant variance condition is satisfied.]

---

## Checking normality

```{r, fig.height = 2.5}
resid_hist <- ggplot(data = sat_aug, aes(x = .resid)) + 
  geom_histogram() + 
  theme_bw() +
  labs(x= "Residuals")

resid_qq <- ggplot(data = sat_aug, aes(sample = .resid)) + 
  stat_qq() + 
  stat_qq_line() +
  labs(x = "Theoretical quantile", 
       y= "Observed quantile") +
  theme_bw()

resid_hist + resid_qq
```

--

`r emo::ji("warning")` .vocab[Normality is not satisfied]. However, $n>30$, so by the Central Limit Theorem, we can still do inference about the model parameters.

---

## Checking independence

- We can often check the independence condition based on the context of the data and how the observations were collected.

- If the data were collected in a particular order, examine a scatterplot of the residuals versus order in which the data were collected. 

- If there is a grouping variable lurking in the background, check the residuals based on that grouping variable.


---

## Checking independence

Since the observations are US states, let's take a look at the residuals by region. 

```{r}
regions <- bind_cols(state.name, state.region) %>%
  rename(State = "...1",
         Region ="...2" ) %>%
  mutate(state_name = str_replace(State, " ",""))

sat_data <-  Sleuth3::case1201 %>%
  mutate(obs_num = 1:nrow(Sleuth3::case1201))

sat_aug <- left_join(sat_aug, sat_data, by = "obs_num")

states <- right_join(regions, sat_aug, by = c("state_name" = "State"))
```
```{r fig.height = 2.5}
p1 <- ggplot(data = states, aes(x = .fitted, y = .std.resid, color = Region)) +
  geom_point() + 
  geom_hline(yintercept = 0)  +
  labs(x = "Predicted", 
       y = "Residuals", 
       color = "US Regions")

p2 <- ggplot(data = states, aes(x = Region, y = .std.resid)) +
  geom_boxplot() + 
  geom_hline(yintercept = 0)  +
  labs(x = "U.S. Region", 
       y = "Residuals")

p1 + p2
```

---

## Checking independence

`r emo::ji("x")` The model tends to overpredict for states in the South and underpredict for states in the North Central, so the .vocab[independence condition is not satisfied].

Multiple linear regression is **not** robust to violations of independence, so before moving forward, we should try fitting a model that includes **region** to account for these differences by region. 


